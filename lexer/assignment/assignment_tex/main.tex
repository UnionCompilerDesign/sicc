%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% fphw Assignment
% LaTeX Template
% Version 1.0 (27/04/2019)
%
% This template originates from:
% https://www.LaTeXTemplates.com
%
% Authors:
% Class by Felipe Portales-Oliva (f.portales.oliva@gmail.com) with template 
% content and modifications by Vel (vel@LaTeXTemplates.com)
%
% Template (this file) License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	12pt, % Default font size, values between 10pt-12pt are allowed
	%letterpaper, % Uncomment for US letter paper size
	%spanish, % Uncomment for Spanish
]{fphw}

% Template-specific packages
\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage{mathpazo} % Use the Palatino font

\usepackage{graphicx} % Required for including images

\usepackage{booktabs} % Required for better horizontal rules in tables

\usepackage{listings, listings-rust} % Required for insertion of code

\usepackage{enumerate} % To modify the enumerate environment

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Assignment \#1: Building a Lexer} % Assignment title


\date{DUE DATE} % Due date

\institute{Union College} % Institute or school name

\class{CSC-375 Compiler Design} % Course or class name

\professor{Aaron Cass} % Professor or teacher in charge of the assignment

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Output the assignment title, created automatically using the information in the custom commands above

%----------------------------------------------------------------------------------------
%	ASSIGNMENT CONTENT
%----------------------------------------------------------------------------------------

\section*{Objectives}

\begin{problem}
	\begin{itemize}
	    \item Familiarize yourself with the Rust programming language
        \item Complete the first part of code compilation, breaking a program string into lexical tokens
        \item Pass all tests given in \textit{lexer\_tests.rs}
        \item Work in groups of 2-3
        
	\end{itemize}
\end{problem}

%------------------------------------------------

\subsection*{An explanation of lexing:}
From a high level, it might look like this step isn't even necessary. Why would we need to process our code at all before trying to compile it? We already wrote it and all the syntax highlighting checks out, isn't that enough? \\
\\
Behind the scenes, your text editor is doing a lot of heavy lifting. As humans we can easily read over our code that has comments and whitespace and structure, but to a computer this means nothing. From a computer's perspective, all it sees is one giant long list of characters next to each other with no natural way to see what it all "means".\\
\\
The point of a lexer is to take this giant string and try to make it a little more readable by a computer program, for example transforming something like "true || false" into the list of tokens [TRUE, OR, FALSE]. Doing this step will make our jobs much easier going forward and will allow us to have a more easily readable list of tokens instead of a raw list of characters to try and work with.

\pagebreak
%----------------------------------------------------------------------------------------

\section*{Lexer Structure}


	\lstinputlisting[
		caption=lib.rs, % Caption above the listing
		label=lst:modlexer, % Label for referencing this listing
		language=Rust, % Use Rust functions/syntax highlighting
		frame=single, % Frame around the code listing
		showstringspaces=false, % Don't put marks in string spaces
		numbers=left, % Line numbers on left
		numberstyle=\tiny, % Line numbers styling
	]{lib.rs} % file name to list


\section*{lib.rs:}
This file defines the modules related to the lexer and makes them available for other modules to see. You can see this in the \textit{lexer/} folder. All modules have documentation in this file to show what the module is used for. The lexer is relatively simple, so all it has is a module containing the tokens it can use and the lexer itself.\\
\\
You don't have to do anything to this file.

\section*{token.rs:}
This file contains an \textbf{enum} which houses all of the tokens we have available to break the string into. The final output will be a \textbf{vector} (sort of like a list) of these tokens. For example, if when scanning through the program string you encounter a '(', you should probably add Token::LPAREN to your output vector. Other tokens will be more complex to detect.\\
\\
Again, you don't have to do anything here. All of these tokens are given.

\section*{lexer\_core.rs:}
This is where the magic happens. This file is where the structure for taking a string input and scanning through it to create a list of tokens exists. \\
\\
All of the functions here have been intentionally left blank, and none of the tests will pass. That's kind of a problem since we need our lexer to function, so this is where you come in. 

\pagebreak

\section*{Follow these guidelines to build the lexer structure in lexer\_core.rs}

\begin{problem}
    \begin{enumerate}
        \item Do not change any of the function signatures, i.e. leave all parameters, parameter types, and return types as you found them.
        \item Follow all instructions given in the comments where they exist, and take any potential hints into consideration when making your design.
        \item Remember you are scanning through a string one character at a time, but at times (such as with variable and function identifiers) you may need to collect more than one character for a token, this is okay.
        \item Remember to check if a character is what you think it is before pushing a token to the output vector. If you see '<' that might be part of "<=", never assume!
        \item Start early. This may seem simple, but for many of you this is an entirely new language experience, and some concepts may take time to get used to.
        
    \end{enumerate}
\end{problem}

\section*{Cheat sheet for creating tokens}

\begin{problem}
    it might not be obvious how to create tokens before pushing them to the output vector, so here are some tips on how to do this.
    \\
    \begin{enumerate}
        \item Tokens are part of the \textbf{Token enum} as showed before, so when creating one use "Token::" to signal you want to make an item from the Token enum, followed by the token's name. For example, if I want a token for '*' the token I want would be \textbf{Token::ASTERISK}.
        \item For tokens that have no data (such as a left parenthesis for example) creating tokens is simple. If I detect a left parenthesis, then I would push \textbf{Token::LPAREN} to the output vector.
        \item Some tokens have many characters at once, for example the integer "42". Once you have all characters collected in a vector of characters (we'll call it \textbf{vec}) you can create a token with data in it by specifying the name of the token like above and then, in parentheses, the data you want to attach. For "42" I would create \textbf{Token::INT(vec)}.
    \end{enumerate}
\end{problem}

\pagebreak


\end{document}
